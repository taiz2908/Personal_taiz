Ref: 
 1. - https://www.youtube.com/watch?v=7xngnjfIlK4&t=1716s
    - https://github.com/sidpalas/devops-directive-terraform-course

 2. https://www.youtube.com/watch?v=iRaai1IBlB0&t=8s

 3. https://www.youtube.com/watch?v=SLB_c_ayRMo&t=51s Terraform Course - Automate your AWS cloud infrastructure

 4. https://www.youtube.com/watch?v=iRaai1IBlB0&t=6s Learn Terraform (and AWS) by Building a Dev Environment â€“ Full Course for Beginners

============================: INTRODUCTION :=================================================================
 - IAC - Infrasstructure as a code. (create,manage,delete by using the code)
 - Cloudformation(2011): Automated infrastructure in AWS.
    Mitchell Hashimoto - 2014
 - Open source and supports all clouds .
 - Written in Go Language.
 - Uses HCL (Hasicorp configure Language), similar to JSON.
 - Two ways to approach.
   1. Imperative
   2. Declarative
 - Reuse the code. 
 - File extension with .tf (terraformfile)

Others IAC / Alternative : Pulumi, CloudFormation by AWS. 

 --------------------------
 Installation:
  On windows:
   - paste .exe file in programsfiles folder
   - go to env variable set the path-->click on path-->new ->paste the actual path-->ok
   - open cmd and type terraform version ?
---------------------------
 Block & Arguments:
  - resource: Block name-->1st
  - local_file: <provider>_<resource_type>: Resource type-->2nd
  - pets: <resource_name> -->3rd
  - {}: Arguments -->4th
Example:
 resource "local_file" "pet" {
    filename = "/root/pets.txt"
    content = "I love dogs!"
 }
Note:
 - We can create multiple resource in one file. 

Ex:
 resource "random_string" "rand-str" {
    lenght = 12
    special = true
    override_special = "{}/*&[]"
 }
 output "rand-str" {
    value = random_string.rand_str[*].result
 }
-----------------------------------------------------
Providers:
 - Responsible for understanding the API interaction.
 - <provider>_<resource_type>: Resource type-->2nd
 - automatically created the file and before we need to run terrafrom init.
 - downloaded the plugins for providers.
AWS : aws
Azure: azurerm
Google: google
Alibaba cloud: alicloud

Terraform cmds:
 # terraform init
 # terraform validate
 # terraform plan
 # terraform plan --refresh-only
 # terraform apply --auto-approve
 # terraform destroy
Other Cmds:
 # terraform fmt: The terraform fmt command is used to rewrite Terraform configuration files to a canonical format and style
 # terraform state list , lists all resources
 # terraform state show <resource_name> , gives a detailed output
 # terraform output
 # terraform refresh, refresh all of the states without applying any changes and prints the outputs.

Target Resources: using of "-target" flag
 # terraform apply -target <resource_type>.<resource_name>  , creating specific one resource
 # terraform destroy -target <resource_type>.<resource_name> , destroying specific one resource. 

1. Terraform Init:
The terraform init command creates a working directory(.terraform) in which Terraform configuration files can be found. 
 - Initializing the backend.../ initializing providers plugins...
 - Installing required plugins.
 - Reusing previous version
 - Finding latest version of hasicorp
 - Installing hasicorp local
 - Terraform has been successfully initialized

2. Terraform validate
 - Mostly use to validate the syntax i.e.,missing trailing codes, or equal signs, some modules declar's multiple times etc. 
 - Shows the message: Success! The configuration is valid. 

3. Terraform Plan: "dry run"
 - compaired desired state with actual state.
 - it will perform the following actions.
 - it'll display show after apply 

4. Terrafrom apply:
 - it will ask for these actions Yes or No

===================================: terraform.tfstate  :====================================================
Ref: 
 - https://www.youtube.com/watch?v=5FkcC_w3xQM&t=39s
 - https://www.youtube.com/watch?v=q5-zsBY90j8

What is .tfstate ?
 - Whatever it'll create it's lock those things.(stores all of those resources we have created)
 - JSON file: contains informations about every resource and data object. 
 - Contains sensitive info- database password etc
 - can be stored locally or remotely (S3, Google cloud storage etc)

How to Store Terraform State File In AWS S3?
 - Store in S3 Bucket.In the main.tf we need to write backend "s3" {}
 - Need to create S3 Bucket. 
 - Create a policy & role in aws IAM.
 - Create Dynamodb & need to create a dynamodb table --> basically locking the state file.
   Ex: If two users running parallely / executive the scripts. will not allow. 
 - Go inside main.tf / backend.tf .
Ex:
   terraform {
    backend "s3" {
    encryption = "true"
    bucket = "mycmpy-tf-state"
    region = "us-east-1"
    kms_key_id = "terraform-state/anyname.tfstate"
    dynamo_table = "terraform-lock"
    role_arm = "arn:aws:iam:{}-role/terraform-state-s3"
      }
    }

===================: Terraform with Docker: ==========================================================
 - Terraform Block: Install required providers, versions etc
 - source
 - version
 Ex:
terraform {
  required_providers {
    docker = {
      source  = "kreuzwerker/docker"
      version = "3.0.1"
    }
  }
}
provider "docker" {
  host = "unix:///var/run/docker.sock"
}

# Pulls the image
resource "docker_image" "nginx" {
  name         = "nginx:latest"
  keep_locally = false
}

# Create a container
resource "docker_container" "nginx" {
  image = docker_image.nginx.latest
  name  = "nginx-tf"
  ports {
    internal = 80
    external = 80
  }
}
================== :Terraform AWS: ==========================================================
# creating the EC2 Services.
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }
}

How to generate the Key from AWS Console?
 - IAM-> Create users-> Tik on access key-> permissions-> attached the policies.
 - Download Access keyID & Secrete Access key
# providing the resgion, access_key & secrete_access key. 
provider "aws" {
  region     = "us-west-2"
  access_key = "my-access-key"
  secret_key = "my-secret-key"
}

Note: 
 - If we don't provide the region it'll create in bydefault region i.e., "us-east-1"

# Need to provide ami, instance type & instance id.
resource "aws_instance" "web1" {
  ami           = "data.aws_ami.ubuntu.id"
  instance_type = "t3.micro"
  tags = {
    Name = "server1"
  }
}

resource "aws_instance" "web2" {
  ami           = "data.aws_ami.ubuntu.id"
  instance_type = "t3.micro"
  tags = {
    Name = "server2"
  }
}
# Can able to see public IP
output "ec2_public_ips" {
  Value = aws_instance.web1.public_ip 
}
# Creating a S3 Bucket
resource "aws_s3_bucket" "bucket" {
  bucket = "my-tf-test-bucket"
  tags = {
    Name        = "my-tf-test-bucket"
    Environment = "Dev"
  }
}

# Creating AWS VPC Using Terraform:
 - VPC
 - Subnet
 - Internet Gateway
 - Route Table 
 - Subnet Associations
 - Security Groups
 - EC2 Instance
Ex: https://github.com/taiz2908/DevOps_Projects/tree/main/terraform
 # route table/vpc/security groups/ resource for terraform
Ex: 
 - https://www.youtube.com/watch?v=SLB_c_ayRMo&t=51s
 - https://github.com/Sanjeev-Thiyagarajan/Terraform-Crash-Course

========================: Terraform Variables & Outputs: ===================================================

Ref: https://developer.hashicorp.com/terraform/language/values/variables

Variable Types:
1. Input variables:
 - Ex: string, num, bool etc. 
 - Here we have to define two fies. 
   - main.tf
   - variable.tf

Ex: 
- main.tf , file
resource "aws_instance" "web1" {
  ami           = var.ami_type
  instance_type = var.instance_type
  tags = {
    Name = "server1"
  }
}

- variable.tf, file
Ex:
  variable "ami_type" {
  description = "ec2 instance type"
  type        = string
  # default     = "data.aws_ami.ubuntu.id"
}
  variable "instance_type" {
  description = "ec2 instance type"
  type        = string
  # default     = "t2.micro"
}

2. Local Variables: Temporary variables.can reuse,  Take a value repeatadely 
   - local.<name>

3. Output Variables:
   - Allows you to output some value mostly use for knowing the public ip. 
Ex:
 output "" {
  value = 
 }

Setting Input variables:
 - manual entry during apply/plan
 - default value in declaration block
 - TF_VAR_<NAME> Env variables
 - terraform.tfvars files  --> we can define the values for the variable, non-sensitive. 
 - *.auto.tfvars file
 - command line -var or -var-file

Ex: 
main.tf --> 
   - define our backend & providers
   - we can define local variables. 
   - we can define variables i.e., var.ami , var.instance_name etc

outputs.tf -->
   - gives the output values.
   - public ip, private ip, key pairs etc

variables.tf --> 
   - vars mentioned under variables.tf file & can change during run time

terraform.tfvars --> 
   - Assigned a value.
   - default name with the name "terraform.tfvars"
   - we can define the values for the variable, non-sensitive. 

another-variable-file.tfvars -->
   - explicitly tell when we do terraform apply
   - terraform apply -var-file= 

===========================: Additional Language Features :=======================================================
Meta- Arguments:
1. depends_on:
    - Terraform automatically generats dependency graph based on reference. 
    - Ex:
     If we want to create the resource aws_iam_role_policy before aws_instance, hence we should define depends_on under aws_instace
     so that aws_instance would fail if attending to create it before the aws_iam_role_policy.

2. count:
    - if want to create multiple resources/copies then we can use count under resource. 
    - useful if we have multiple resources nearly "identical". 
  Ex:
  resource "aws_instance" "server" {
  count = 4 # create four similar EC2 instances
  ami           = "ami-a1b2c3d4"
  instance_type = "t2.micro"
  tags = {
    Name = "Server ${count.index}"
  }
}

3. for_each:
    - kind of count arg but much more control of it to "customise".
    - use to create multiple resource.

4. Lifecycle: Lifecycle meta-arguments control how Terraform treats particular resources.
    - create_before_destroy = true: indicates that if the resource does need to be destroyed, 
    Terraform should first provision its replacement before destroying the deprecated resource. 
    This can be useful for things such as zero downtime deployments.
    - ignore_changes: Sometimes an entity outside of terraform will automatically modify a resource (e.g. adding metadata, etc...). 
    The ignore_changes argument allows you to ignore specific types of resource changes to prevent this from causing Terraform to attempt to revert those changes.
    - prevent_destroy: provides an additional stopgap against accidentally destroying resources with terraform. 
    If set to true, Terraform will reject any attempt to destroy that resource. 
-------------------------------
Provisioners:
 - Allows you to Perform action on local / remote m/c's.
 - Ex: file, local-exec, remote-exec, vendor(chef,puppet,ansible)

===========================: Data Sources :===================================================================  
 - Data sources allow Terraform to use information defined outside of Terraform, defined by another separate Terraform configuration, or modified by functions.
 - A data source is accessed via a special kind of resource known as a data resource, declared using a "data block:
 - Ex: Subnet already created and we can pass it by using data source.
EX:
resource "aws_instance" "web" {
  ami           = data.aws_ami.web.id
  instance_type = "t1.micro"
}

===========================: Project Org + Modules :============================================================
Ref: 
 - https://www.youtube.com/watch?v=W92fsWzVRsg , What are Terraform Modules | Modules in Terraform | Terraform Modules Examples 
 - https://www.youtube.com/watch?v=ZP_vAbjfFMs , Use Terraform Module to Build a 3 Tier AWS Network VPC
 - https://www.youtube.com/watch?v=Ta4gPMpfPgg , Terraform Best Practices | Writing Terraform Modules | Terraform tutorial |

Before starting we should know what is "Dry principle"?
 - specifically applied for the software development area. 
 - don't repeat yourself.
 - no need to write the code again & again. 

Modules: "Reusuable codes"
 - As terraform configurations become more complex, module can be used to organise and simplify them.
 - Also we can share the module within our organisation & with the terraform communities.
 - Module are containers for multiple resources that are used together. 
 - Collection of .tf and /or .tf.json files kept together in a directory.
 - Modules are the main way to package and resuse resource configuration with Terraform.
 
Types:
 1. Root Module:
    - default module containing all .tf files in main working dir.
 2. Child Module: 
    - A separate external module referred to from a .tf file.

Module Sources:
 - local path, terraform registry, github, bitbuckeet, s3, gcs bucket etc

Ex: How we call main.tf in module?
 module "vpc" {
   source = "./modules/aws_vpc"
 }
 module "subnet" {
   source = "./modules/aws_subnet"
 }

===========================: Managing Multiple Env :============================================================
Dev / SIT/ PROD ETC
1. File Structure
2. Workspace

Terragrunt:
 - tool by gruntwork.io --> meta tooling can be apply on the top of that terraform 
 - Keep your Terraform code DRY, Define Terraform code once, no matter how many environments you have.
 - Keep your backend configuration DRY, Get rid of duplicated backend code.
 - less complexcity. 

=======================================: INTERVIEW QUS :===========================================================
Interview Qus:
 1. https://k21academy.com/terraform-iac/terraform-interview-questions/
 2. https://www.youtube.com/watch?v=t9bHZMFxQYY&t=110s

1. How to change's the configuration of already created resources by terraform?
 - # terraform import 
 - # terraform import [options] ADDRESS ID
 - It's bring the resources into the .tfstate file.
 - https://developer.hashicorp.com/terraform/cli/commands/import
 - https://www.youtube.com/watch?v=l2R_tl1I7cA
 - https://www.youtube.com/watch?v=YYQ6W90ZsY4

2. When the terraform runs , terraform.tfstate file created ?
 - Whatever it'll create it's lock those things. (stores all of those resources we have created)
 - JSON file: contains informations about every resource and data object. 
 - Contains sensitive info- database password etc
 - can be stored locally or remotely (S3, Google cloud storage,Azure storage a/c etc)
 
3. Some how if you loose the terraform.tfstate file then ?
 - terraform import
 - Unable to find the .tfstate file.
 - If we try to recreate it,Cost will increase & duplication will be done
 - it's create from initial so to avoide this we can use the command terraform import.

4. Features of Terraform?
 - Can use / manage in multiple cloud's.
 - Can use HCL easy to understand i.e., human reable 
 - 

5. Pulumi:
 - can use any language like python, typescript 
 - more flexible 

6. Modules in Terraform ?
 - Refer to Note.

7. Remote Back end in Terraform ?
 - A backend defines where Terraform stores its state data files.
 - Makes easier to the team to work together and all the members have the access to the latest state data
 - work as storage , and users can share the same infrastructure resrouces. 
 - Two types of Backend (Local & Remote)

8. How do we provide variable value in run time ?
 -  If we commented out "default" value in variable.tf file.

 variable "ami_type" {
  description = "ec2 instance type"
  type        = string
  # default     = "data.aws_ami.ubuntu.id"
}

9. Multiple Env , is there any way to manage ?
 - Terraform workspace: Allows to manage separate state file for each workspace.
 - Reusable Module: This is an Architecture where configuration files are stored in a single directory with module
 block can source that directory into and pass to that variable.

10. Terraform latest Versions:
 - terraform_1.5.0-alpha20230405
 - terraform_1.4.4
 - terraform_1.4.3

11. Disadvantage of Terraform:
 - state file is the single source of truth.
 - Manual changes to the cloud provider cann't be identified  and auto corrected.

12. Deploy all the resources into correct order? How to do that?
 - Meta- Arguments: "depends_on"
    - Terraform automatically generats dependency graph based on reference. 
    - Ex:
     If we want to create the resource aws_iam_role_policy before aws_instance, hence we should define depends_on under aws_instace
     so that aws_instance would fail if attending to create it before the aws_iam_role_policy.

13. Need to create the multiple instances of the same resources with slightly diff configurations, How to do that?
 - By using "count" meta arg. 

14. Need to create ec2 instance using terraform, then execute a shell script after it has been created how to do that?
 - Execute the "remote-exec" provisioners. 
 Ex:
 provisioner "remote-exec" {
  inline = [
    "sudo yum -y update",
    "sudo yum install -y httpd"'
  ]
 }
=======================================================================================================
Ref: https://www.youtube.com/watch?v=pCoCynze4Ag

1. Daily activities that you do in Terraform?
 - Changes
 - Any New applications, resources based on that 
 - Any team facing some issue's.

2. What are services that you have worked with and wrote terraform files?
3. Tell me a scenario where you come across provisioners?

4. What are plugins and providers in terraform?
 - Based on the provider's plugins going to download.

5. How do you deploy the terraform code manually or with some automation? Have configured locks on the backend statefile?
 -  
===============================================================
Ref: https://www.youtube.com/watch?v=7lIlR0hXCY8
1. Can we use Terraform in on-prem infra?
 - Yes, We need providers .

2. Does Terraform supporys Multi-provider deployment?
 - Yes, 

3. All versions supported Terraform?
 - Github
 - Gitlab
 - Bitbucket
 - Github Enterprime edition

4. Components of Terraform Architecture?
 - Providers
 - Resource --> Mandatory component
 - Variables.tf
 - terraform.tfstate
 - output.tf 
 - .terraform --> dir containes modules & plugins used to provision the infrastructure. 
 - .tfvars

5. How to store sensitive data in Terraform ?
 - 

6. State file locking ?
 - Why ? apply --> multiple user's , to protect the duplication 

7. 
 
============================: PROJECT :===================
Ref: 
 - https://www.youtube.com/watch?v=fgpec0gvuJQ&list=PLLu1bCv5AByF1wC7epZHGAjfhmDR5XKK7&index=15
Jenkins install using terraform | Run Shellscript on ec2 using ssh.
1. Authenticate terraform with aws creds
2. create default vpc if not exist 
3. use data source to get all availability zones in a region
4. create default subnet if one doesn't exist 
5. Create security group for the jenkins instance
6. create jenkins server 
7. create null resource and execute install_jenkins.sh script
---
provider "aws" {
  region = var.
  access_key = var.
  secret_key = var.
}
---
resource "aws_default_vpc" "default" {
  tags = {
    Name = "Default VPC"
  }
}
// resource tag when to use , when we're going to create new resource
// data tag when to use , use when we have resource already created/existing. 
---
data "aws_availability_zones" "available" {
  state = "available"
}
---
resource "aws_default_subnet" "default_az1" {
  availability_zone = data.aws_availability_zones.available.names[0]

  tags = {
    Name = "Default subnet for us-west-2a"
  }
}
---
resource "aws_security_group" "allow_tls" {
  name        = "allow_tls"
  description = "Allow TLS inbound traffic"
  vpc_id      = aws_default_vpc.default.id

  ingress {
    description      = "SSH Access"
    from_port        = 22
    to_port          = 22
    protocol         = "tcp"
    cidr_blocks      = [aws_vpc.main.cidr_block]
  }
   ingress {
    description      = "HTTP Access"
    from_port        = 8080
    to_port          = 8080
    protocol         = "tcp"
    cidr_blocks      = [aws_vpc.main.cidr_block]
  }

  egress {
    from_port        = 0
    to_port          = 0
    protocol         = "-1"
    cidr_blocks      = ["0.0.0.0/0"]
  }

  tags = {
    Name = "allow_tls"
  }
}
---
resource "aws_instance" "jenkins_server" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t3.micro"
  subnet_id = aws_default_subnet.default_az1.id
  vpc_security_group_ids = [ aws_default_vpc.default.id ]
  key_name = "****"


  tags = {
    Name = "HelloWorld"
  }
}
---
resource "aws_instance" "web" {
  # ...

  # Establishes connection to be used by all
  # generic remote provisioners (i.e. file/remote-exec)
  connection {
    type     = "ssh"
    user     = "ubuntu"
    password/private_kay = var.root_password/file("~/downloads/demo.pem")
    host     = self.public_ip
  }

  provisioner "remote-exec" {
    inline = [
      "puppet apply",
      "consul join ${aws_instance.web.private_ip}",
    ]
  }
}
==========================